# -*- coding: utf-8 -*-
"""Phiên bản 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dQkgHT4KYFnVbO8QuCJq_6g1aKU9uWcW

**Nhiệm vụ chính**
* Lấy dữ liệu
* Xử lý như thế nào:
1.   Loại bỏ cột không cần thiết
2.   thay thế các ô thiếu dữ liệu bằng số 0
3.   Chuẩn hóa dữ liệu 0 và 1
* Trực quan dữ liệu : số ca nhiễm và số ca tử vong
* Lưu trữ dữ liệu bằng csv, excel, lưu ở github hoặc lưu trên máy tính

Đề bài: XỬ LÝ DỮ LIỆU ĐỂ DỰ BÁO DIỄN BIẾN
DỊCH BỆNH COVID 19 cho các nước: Nhật bản, việt nam, hàn quốc, thái lan
* Lưu ý: dữ liệu phục vụ cho bài toán Logistic Regression .
* Yêu cầu phải cột như sau: new_cases,  new_deaths, date,iso_code
* Mục tiêu: Hiểu bài toán logictis regression, so sánh dự báo của mình và kết quả thực tế, dữ liệu đơn: tổng số ca nhiễm và tổng ca tử vong

# **Dữ liệu đầu vào**


1. iso_code: Mã quốc gia.
2. continent: Khu vực quốc gia
3. location: vị trí địa lý
4. date: Ngày tháng năm
5. new_cases: Tổng số trường hợp được xác nhận của COVID-19.
6. new_deaths: Tổng số ca tử vong do COVID-19.

# **Mục tiêu mong muốn**
Dự báo ca nhiễm và ca tử vong vào ngày 01/01/2023 của 4 quốc gia: Nhật bản, Hàn Quốc, Thái Lan, Việt Nam

# **LẤY DỮ LIỆU**
"""

# Gọi thư viện cần thiết
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt # Thư viện  trực quan hóa
plt.rc("font", size=14) # đặt kích thước font chữ là 14
import seaborn as sns # trực quan hóa dữ liệu
sns.set(style="white") # Vẽ phong nền trắng và không đường viền
sns.set(style="whitegrid", color_codes=True) # Vẽ nền trắng, có đường viền
from tabulate import tabulate
# Lấy dữ liệu từ Tổ Chức WHO
url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'
# Đọc dữ liệu
data = pd.read_csv(url)
# Chuyển đổi cột 'date' thành kiểu dữ liệu datetime
data['date'] = pd.to_datetime(data['date'])
# In ra dữ liệu sau khi lọc
grouped_df = data.head(100)
table = grouped_df.reset_index(drop=True)
print(tabulate(table, headers='keys', tablefmt='psql'))

print("Thông tin tổng quan về dữ liệu:")

# Tìm ngày cập nhật mới nhất dữ liệu
latest_update = data['date'].max()
#Tìm ngày bắt đầu ghi dữ liệu
latest_begin = data['date'].min()
# Tính số lượng giá trị duy nhất trong cột 'location'
num_countries = len(data['location'].unique())
# Xuất kết quả
print("Ngày bắt đầu ghi dữ liệu :", latest_begin)
print("Ngày cập nhật dữ liệu mới nhất:", latest_update)
print("Số lượng quốc gia: ", num_countries)
print(data.info())

"""# **XỬ LÝ DỮ LIỆU**"""

# Import thư viện pandas và tabulate
import pandas as pd
from tabulate import tabulate
# Chọn các quốc gia cần hiển thị
countries = [ 'Japan', 'South Korea', 'Thailand','Vietnam']
filtered_df = data[data['location'].isin(countries)]
grouped_df = filtered_df.groupby('location').head(7)
# Tạo bảng và hiển thị
table = grouped_df.reset_index(drop=True)
print(tabulate(table, headers='keys', tablefmt='psql'))

# Chọn các cột hiển thị
dropdata = filtered_df[["iso_code", "location", "date", 'new_cases', 'new_deaths']]
# Tạo bảng và hiển thị
table = dropdata.reset_index(drop=True)
print(tabulate(table, headers='keys', tablefmt='psql'))
print(dropdata.info())

# Kiểm tra dữ liệu có cột âm trong new_cases và new_deaths của 4 quốc gia
# Kiểm tra và thông báo nếu có giá trị âm trong cột 'new_cases'. Nếu có thay thế bằng 0
if any(dropdata['new_cases'] < 0):
    for index, row in dropdata.iterrows():
        if row['new_cases'] < 0:
            print(f"Giá trị âm {row['new_cases']} tại vị trí {index} trong cột 'new_cases'. Sẽ thay thế bằng 0.")
            dropdata.at[index, 'new_cases'] = 0
else:
    print("Không có giá trị âm trong cột new_cases")
# Kiểm tra và thông báo nếu có giá trị âm trong cột 'new_deaths'
if any(dropdata['new_deaths'] < 0):
    for index, row in dropdata.iterrows():
        if row['new_deaths'] < 0:
            print(f"Giá trị âm {row['new_deaths']} tại vị trí {index} trong cột 'new_deaths'. Sẽ thay thế bằng 0.")
            dropdata.at[index, 'new_deaths'] = 0
else:
    print("Không có giá trị âm trong cột new_deaths")

# loại bỏ dữ liệu trùng lập  của 4 quốc
# Kiểm tra dữ liệu trùng lặp. Nếu có thì loại bỏ
duplicates = dropdata[dropdata.duplicated(subset=['location', 'date'], keep=False)]
if not duplicates.empty:
    print("Có dữ liệu trùng lặp:")
    for index, row in duplicates.iterrows():
        print(f"Vị trí {index}: Quốc gia {row['location']}, ngày {row['date']}")

    # Loại bỏ dữ liệu trùng lặp
    deduplicated_data = dropdata.drop_duplicates(subset=['location', 'date'], keep='first')

    # Thông báo đã loại bỏ dữ liệu trùng lặp
    print("\nĐã loại bỏ dữ liệu trùng lặp.")
else:
    print("Không có dữ liệu trùng lặp.")
    deduplicated_data = dropdata

# Xử lý dữ liệu bị thiếu bằng cách chèn số 0
# Kiểm tra dữ liệu thiếu
deduplicated_data = dropdata.isna()
if deduplicated_data.any().any():
    print("Có dữ liệu thiếu:")
    for col in ['new_cases', 'new_deaths']:
        missing_rows = deduplicated_data[col]
        if missing_rows.any():
            print(f"Dữ liệu thiếu trong cột {col}:")
            for index, value in missing_rows.iteritems():
                if value:
                    print(f"Vị trí {index}: Quốc gia {dropdata.at[index, 'location']}, ngày {dropdata.at[index, 'date']}")

    # Xử lý dữ liệu thiếu bằng cách chèn số 0
    deduplicated_data = dropdata.fillna(0)

    # Thông báo đã xử lý dữ liệu thiếu
    print("\nĐã xử lý dữ liệu thiếu bằng cách chèn số 0.")
else:
    print("Không có dữ liệu thiếu.")
    deduplicated_data = dropdata
# Hiển thị dữ liệu sau khi xử lý (Minh họa)
# grouped_df = deduplicated_data.groupby('location').head(7)
# table = grouped_df.reset_index(drop=True)
# print(tabulate(table, headers='keys', tablefmt='psql'))

# # Thống kê dữ liệu đã xử lý
# # Ca nhiễm
# # Trích xuất giá trị năm từ cột "date"
# deduplicated_data['year'] = deduplicated_data['date'].dt.year
# # Chọn các năm cần thống kê
# years = [2020, 2021, 2022, 2023]
# # Thống kê số ca nhiễm của các quốc gia theo từng năm
# summary = deduplicated_data[deduplicated_data['year'].isin(years)].groupby(['location', 'year'])['new_cases'].sum()
# # Đặt tên cho các cột trong DataFrame
# summary = summary.reset_index()
# summary.columns = ['Quốc gia', 'Năm', 'Tổng số ca nhiễm·']

# # Hiển thị kết quả
# print("Tổng số ca nhiêm·")
# print(summary)
# # Ca Tử vong
# # Trích xuất giá trị năm từ cột "date"
# deduplicated_data['year'] = deduplicated_data['date'].dt.year
# # Chọn các năm cần thống kê
# years = [2020, 2021, 2022, 2023]
# # Thống kê số ca nhiễm của các quốc gia theo từng năm
# summary = deduplicated_data[deduplicated_data['year'].isin(years)].groupby(['location', 'year'])['new_deaths'].sum()
# # Đặt tên cho các cột trong DataFrame
# summary = summary.reset_index()
# summary.columns = ['Quốc gia', 'Năm', 'Tổng số ca tử vong ·']

# # Hiển thị kết quả
# print("Tổng số ca nhiêm·")
# print(summary)
import matplotlib.pyplot as plt
import seaborn as sns

# Lọc dữ liệu cho 4 quốc gia cần thống kê
countries = ['Japan', 'South Korea', 'Thailand', 'Vietnam']
filtered_data = deduplicated_data[deduplicated_data['location'].isin(countries)]

# Thống kê tổng số ca nhiễm và tổng số ca tử vong theo từng năm và quốc gia
summary = filtered_data.groupby(['year', 'location']).agg({'new_cases': 'sum', 'new_deaths': 'sum'}).reset_index()

# Trực quan hóa dữ liệu
plt.figure(figsize=(12, 6))

# Biểu đồ tổng số ca nhiễm
plt.subplot(1, 2, 1)
sns.barplot(x='year', y='new_cases', hue='location', data=summary)
plt.title('Tổng số ca nhiễm theo năm và quốc gia')
plt.xlabel('Năm')
plt.ylabel('Tổng số ca nhiễm')
plt.legend(loc='upper right')

# Biểu đồ tổng số ca tử vong
plt.subplot(1, 2, 2)
sns.barplot(x='year', y='new_deaths', hue='location', data=summary)
plt.title('Tổng số ca tử vong theo năm và quốc gia')
plt.xlabel('Năm')
plt.ylabel('Tổng số ca tử vong')
plt.legend(loc='upper right')

plt.tight_layout()
plt.show()

#thống kê mô tả tổng quan về dữ liệu đã xử lý
countries = ['Thailand', 'South Korea', 'Vietnam', 'Japan']
filtered_data = deduplicated_data[deduplicated_data['location'].isin(countries)]
grouped_data = filtered_data.groupby(['location', 'year']).describe()
#Hiện thị toàn bộ output
print(grouped_data)

#Trực quan hóa dữ liệu
# ca nhiễm
import plotly.express as px
start_date = '2022-01-01'
end_date = '2022-12-31'
filtered_df = deduplicated_data[(deduplicated_data['location'].isin(countries)) & (deduplicated_data['date'] >= start_date) & (data['date'] <= end_date)]

# Vẽ biểu đồ 2D
fig = px.line(filtered_df, x='date', y='new_cases', color='location')

# Cấu hình biểu đồ
fig.update_layout(
    title='Thống kê số ca nhiễm theo năm 2022',
    xaxis=dict(title='Ngày'),
    yaxis=dict(title='Số ca nhiễm'),
    legend_title='Quốc gia',
    width=800,
    height=500
)

# Hiển thị biểu đồ
fig.show()
#Trực quan hóa dữ liệu
# ca Tử vong
import plotly.express as px
start_date = '2022-01-01'
end_date = '2022-12-31'
filtered_df = deduplicated_data[(deduplicated_data['location'].isin(countries)) & (deduplicated_data['date'] >= start_date) & (data['date'] <= end_date)]

# Vẽ biểu đồ 2D
fig = px.line(filtered_df, x='date', y='new_deaths', color='location')

# Cấu hình biểu đồ
fig.update_layout(
    title='Thống kê số ca tử vong theo năm 2022',
    xaxis=dict(title='Ngày'),
    yaxis=dict(title='Số ca tử vong'),
    legend_title='Quốc gia',
    width=800,
    height=500
)

# Hiển thị biểu đồ
fig.show()

# # Chuẩn hóa dữ liệu 0 - 1 cho năm 2022 của 4 quốc gia
#Việt Nam
country = 'Vietnam'
filtered_df_vietnam = deduplicated_data[(deduplicated_data['location'] == country) & (deduplicated_data['date'].dt.year == 2022)].copy()
# Tính phân vị ca nhiễm cho Việt Nam
q1_2022_vietnam_cases = filtered_df_vietnam['new_cases'].quantile(0.25)
q2_2022_vietnam_cases = filtered_df_vietnam['new_cases'].quantile(0.50)
q3_2022_vietnam_cases = filtered_df_vietnam['new_cases'].quantile(0.75)
#Mức ngưỡng ca nhiễm của Việt Nam
threshold_vietnam_cases = q2_2022_vietnam_cases
# Tính phân vị ca tử vong cho Việt Nam
q1_2022_vietnam_deaths = filtered_df_vietnam['new_deaths'].quantile(0.25)
q2_2022_vietnam_deaths = filtered_df_vietnam['new_deaths'].quantile(0.50)
q3_2022_vietnam_deaths = filtered_df_vietnam['new_deaths'].quantile(0.75)
#Mức ngưỡng ca tử vong của Việt Nam
threshold_vietnam_deaths = q2_2022_vietnam_deaths
# Tính nhị phân ca nhiễm và ca tử vong của Việt nam
filtered_df_vietnam.loc[:, 'new_cases_binary'] = filtered_df_vietnam['new_cases'].apply(lambda x: 0 if x <= threshold_vietnam_cases else 1)
filtered_df_vietnam.loc[:, 'new_deaths_binary'] = filtered_df_vietnam['new_deaths'].apply(lambda x: 0 if x <= threshold_vietnam_deaths else 1)

#Nhật Bản
country = 'Japan'
filtered_df_Japan = deduplicated_data[(deduplicated_data['location'] == country) & (deduplicated_data['date'].dt.year == 2022)].copy()
# Tính phân vị ca nhiễm cho Nhật Bản
q1_2022_Japan_cases = filtered_df_Japan['new_cases'].quantile(0.25)
q2_2022_Japan_cases = filtered_df_Japan['new_cases'].quantile(0.50)
q3_2022_Japan_cases = filtered_df_Japan['new_cases'].quantile(0.75)
#Mức ngưỡng ca nhiễm của Nhật Bản
threshold_Japan_cases = q2_2022_Japan_cases
# Tính phân vị ca tử vong cho Nhật Bản
q1_2022_Japan_deaths = filtered_df_Japan['new_deaths'].quantile(0.25)
q2_2022_Japan_deaths = filtered_df_Japan['new_deaths'].quantile(0.50)
q3_2022_Japan_deaths = filtered_df_Japan['new_deaths'].quantile(0.75)
#Mức ngưỡng ca tử vong của Nhật Bản
threshold_Japan_deaths = q2_2022_Japan_deaths
# Tính nhị phân ca nhiễm và ca tử vong của Nhật Bản
filtered_df_Japan.loc[:, 'new_cases_binary'] = filtered_df_Japan['new_cases'].apply(lambda x: 0 if x <= threshold_Japan_cases else 1)
filtered_df_Japan.loc[:, 'new_deaths_binary'] = filtered_df_Japan['new_deaths'].apply(lambda x: 0 if x <= threshold_Japan_deaths else 1)

#Thái Lan
country = 'Thailand'
filtered_df_Thailand = deduplicated_data[(deduplicated_data['location'] == country) & (deduplicated_data['date'].dt.year == 2022)].copy()
# Tính phân vị ca nhiễm cho Thái Lan
q1_2022_Thailand_cases = filtered_df_Thailand['new_cases'].quantile(0.25)
q2_2022_Thailand_cases = filtered_df_Thailand['new_cases'].quantile(0.50)
q3_2022_Thailand_cases = filtered_df_Thailand['new_cases'].quantile(0.75)
#Mức ngưỡng ca nhiễm của Thái Lan
threshold_Thailand_cases = q2_2022_Thailand_cases
# Tính phân vị ca tử vong cho Thái Lan
q1_2022_Thailand_deaths = filtered_df_Thailand['new_deaths'].quantile(0.25)
q2_2022_Thailand_deaths = filtered_df_Thailand['new_deaths'].quantile(0.50)
q3_2022_Thailand_deaths = filtered_df_Thailand['new_deaths'].quantile(0.75)
#Mức ngưỡng ca tử vong  của Thái Lan
threshold_Thailand_deaths = q2_2022_Thailand_deaths
# Tính nhị phân ca nhiễm và ca tử vong của Thái Lan
filtered_df_Thailand.loc[:, 'new_cases_binary'] = filtered_df_Thailand['new_cases'].apply(lambda x: 0 if x <= threshold_Thailand_cases else 1)
filtered_df_Thailand.loc[:, 'new_deaths_binary'] = filtered_df_Thailand['new_deaths'].apply(lambda x: 0 if x <= threshold_Thailand_deaths else 1)

#Hàn quốc
country = 'South Korea'
filtered_df_South_Korea = deduplicated_data[(deduplicated_data['location'] == country) & (deduplicated_data['date'].dt.year == 2022)].copy()
# Tính phân vị ca nhiễm cho Hàn Quốc
q1_2022_South_Korea_cases = filtered_df_South_Korea['new_cases'].quantile(0.25)
q2_2022_South_Korea_cases = filtered_df_South_Korea['new_cases'].quantile(0.50)
q3_2022_South_Korea_cases = filtered_df_South_Korea['new_cases'].quantile(0.75)
#Mức ngưỡng ca nhiễm của Hàn Quốc
threshold_South_Korea_cases = q2_2022_South_Korea_cases
# Tính phân vị ca tử vong cho Hàn Quốc
q1_2022_South_Korea_deaths = filtered_df_South_Korea['new_deaths'].quantile(0.25)
q2_2022_South_Korea_deaths = filtered_df_South_Korea['new_deaths'].quantile(0.50)
q3_2022_South_Korea_deaths = filtered_df_South_Korea['new_deaths'].quantile(0.75)
#Mức ngưỡng ca tử vong  của Hàn Quốc
threshold_South_Korea_deaths = q2_2022_South_Korea_deaths
# Tính nhị phân ca nhiễm và ca tử vong của Hàn Quốc
filtered_df_South_Korea.loc[:, 'new_cases_binary'] = filtered_df_South_Korea['new_cases'].apply(lambda x: 0 if x <= threshold_South_Korea_cases else 1)
filtered_df_South_Korea.loc[:, 'new_deaths_binary'] = filtered_df_South_Korea['new_deaths'].apply(lambda x: 0 if x <= threshold_South_Korea_deaths else 1)

# Hiển thị kết quả
combined_df = pd.concat([filtered_df_Japan, filtered_df_vietnam, filtered_df_Thailand, filtered_df_South_Korea])
pd.set_option('display.max_rows', None)
print(combined_df[['iso_code','location', 'date', 'new_cases','new_deaths', 'new_cases_binary','new_deaths_binary']])

# ca nhiễm từ ngày 01/01/2022
#Japan
from __future__ import division, print_function, unicode_literals
import numpy as np
import matplotlib.pyplot as plt
np.random.seed(2) # tạo ngẫu nhiên những không thay đổi
# Khởi tạo giá trị đầu vào
# X = np.array([[0.25, 0.40, 1.11, 5.05, 1.60, 5.55, 5.45, 1.50, 6.00, 6.10, 2.25, 6.00, 3.05, 3.10, 2.50, 5.60, 6.05, 5.10, 6.95, 6.90]])
X = np.array([[0.25, 0.40, 0.11, 2.05, 1.60, 3.55, 2.45, 1.50, 2.00, 2.10, 2.25, 2.00, 3.05, 5.10, 5.50, 5.60, 6.05, 5.10, 6.95, 6.90]])
y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1])

# Tạo ma trận có kích thước tương ứng với X
X = np.concatenate((np.ones((1, X.shape[1])), X), axis=0)
# Định nghĩa hàm sigmoid:
def sigmoid(s):
    return 1 / (1 + np.exp(-s))
# Xây dựng hàm logistic_sigmoid_regression
def logistic_sigmoid_regression(X, y, w_init, eta, tol=1e-4, max_count=10000):
    # Duyệt qua tất cả các mẫu có trong dữ liệu
    w = [w_init] # tạo một list chứa w ban đầu
    it = 0
    N = X.shape[1] # số lượng mẫu trong dữ liệu
    d = X.shape[0] # số lượng đặc trưng mẫu trong dữ liệu
    count = 0 # đếm số lượng lần cập nhật trong w
    check_w_after = 20 # kiểm tra sự thay đổi của w sau mỗi 20 lần lần cập nhật
    # vòng lập while mỗi lần lập là tương ứng với một lần cập nhật w
    while count < max_count:
        # hàm xáo trộn ngẫu nhiên thứ tự của các mẫu trong dữ liệu
        mix_id = np.random.permutation(N)
        # sau đó duyệt qua tất cả mẫu theo thứ tự đã xáo trộn
        for i in mix_id:
            xi = X[:, i].reshape(d, 1) # đặc trưng mẫu thứ i
            yi = y[i] # nhãn thực tế của mẫu thứ i
            zi = sigmoid(np.dot(w[-1].T, xi)) # giá trị dự đoán hiện tại của mẫu thứ i
            w_new = w[-1] + eta * (yi - zi) * xi #cập nhật w
            count += 1
            # stopping criteria
            if count % check_w_after == 0:
                if np.linalg.norm(w_new - w[-check_w_after]) < tol:
                    return w
            w.append(w_new)
            # cuối cùng trả về kết quả
    return w
# Khởi tạo trọng số ngẫu nhiên trong w_init và thực hiện bằng hàm logistic_sigmoid_regression
eta = 0.05 # tốc độ học
d = X.shape[0]
w_init = np.random.randn(d, 1)
w = logistic_sigmoid_regression(X, y, w_init, eta)
# in ra trong số cuối cùng và dự đoán mô hình
print(w[-1])
print(sigmoid(np.dot(w[-1].T, X)))
# Trực quan hóa kết quả
X0 = X[1, np.where(y == 0)][0]
y0 = y[np.where(y == 0)]
X1 = X[1, np.where(y == 1)][0]
y1 = y[np.where(y == 1)]

plt.plot(X0, y0, 'ro', markersize=8)
plt.plot(X1, y1, 'bs', markersize=8)
xx = np.linspace(0, 6, 1000)
w0 = w[-1][0][0]
w1 = w[-1][1][0]
threshold = -w0 / w1 # Ngưỡng
yy = sigmoid(w0 + w1 * xx)
plt.axis([-2, 8, -1, 2])
plt.plot(xx, yy, 'g-', linewidth=2)
plt.plot(threshold, 0.5, 'y^', markersize=8)
plt.xlabel('Số ca tử vong (số ca nhiễm) theo thời gian')
plt.ylabel('predicted probability of pass(dự đoán)')
plt.show()



# #Code này chạy trên máy tính
# ## Lưu dữ liệu trên máy tính ##
# #Lưu trữ dữ liệu dưới dạng file CSV
# filled_data.to_csv('fill_data.csv', index=False)
# # Lưu trữ dữ liệu dưới dạng file Excel
# filled_data.to_excel('fill_data.xlsx', index=False)
# # ## Lưu dữ liệu trên GitHub ##
# !pip install PyGithub # cài gói thư viện PyGithub
# from github import Github
# import os
# # Thông tin đăng nhập Github
# username = "***************"
# password = "**************"
# access_token = "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"
# # Đường dẫn tới file cần đẩy lên Github
# file_path = "D:/Van_Lang/KhoaLuan/fill_data.csv"
# # Kết nối tới Github bằng access token
# g = Github(access_token)
# # Lấy thông tin repo
# repo = g.get_repo("KhoiNguyen-sudo/khoaluan")
# # Đọc nội dung của file
# with open(file_path, 'r') as file:
#     content = file.read()
# # Tạo file trên Github
# try:
#     repo.create_file("fill_data.csv", "commit message", content, branch="main")
#     print(f"File fill_data.csv đã được đẩy lên Github thành công!")
# except Exception as e:
#     print(f"Lỗi: {e}")

a = 8.2 *4 / 10
b = 2.35 * 10 / 4
c = (b* 118 + 8.2*6)/124
print(b)